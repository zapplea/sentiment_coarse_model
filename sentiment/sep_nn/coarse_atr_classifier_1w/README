In this version, consider attributes as one word.
Difference compared with fine-grained model:
1. attribute and sentiment prototypes are vector, not matrix. sentiment prototypes only
have 3;
2. each batch contains several reviews not directly sentences and need to pad reviews to make them have the same sentence numbers.
3. each sentence need to be padded, since each sentence has different number of words.
4. Since aspects of a review(document) is given as vector of probability, we need a threshold to check which aspect is false attribute.
5. In current stage, if there is non-attribute, then p(x|o) = 1, p(o|D) = 1. In this way, the non-attribute is processed the same to fine-grained model


Constraints:
attribute dim = word embedding dim
size of each review can be divided by batch size of sentences.

seed = {'lstm_cell_size': 200,
                'word_dim': 200
                }
self.nn_config = {'attributes_num': 12,
                  'attribute_dim': seed['word_dim'],
                  'words_num': 10,
                  'word_dim': seed['word_dim'],
                  'attribute_loss_theta': 1.0,
                  'epoch': None,
                  'lr': 0.003,  # learing rate
                  'lstm_cell_size': seed['lstm_cell_size'],
                  'atr_score_threshold': 0,  # attribute score threshold for prediction
                  'test_data_size':1000,
                  # reviews' hyper-parameter
                  'batch_size': 15,  # review batch size
                  'sentences_num': 10, # number of sentences in a review
                  'label_atr_threshold': 0.3 # attribute threshold used to eliminate low possibility attributes
                  }

Current problem:
P(a|D)*P(x|a,y)*max(0,la+ly) if add p(a|D), there won't be false attribute???